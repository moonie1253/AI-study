{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d735d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# 주로 사용하는 코드 2 : 인식한 GPU 개수 출력\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0ef32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49897e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./datasets_tf/creditcard.csv', na_values='#NAME?')\n",
    "# 데이터 파일에서 #NAME? 값이 있으면 결즉치(값 비어있거나 존재하지 않는 경우)로 처리\n",
    "# 앞에 점을 찍어줘야 현재 작업 디렉토리 라는 뜻으로 이해 가능함\n",
    "\n",
    "x=df[['V17','V9','V6','V12']]\n",
    "y=df['Class']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101)\n",
    "#random state은 동일 시드를 생성하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb86f20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "284802    0\n",
      "284803    0\n",
      "284804    0\n",
      "284805    0\n",
      "284806    0\n",
      "Name: Class, Length: 284807, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb42eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             V17        V9        V6       V12\n",
      "0       0.207971  0.363787  0.462388 -0.617801\n",
      "1      -0.114805 -0.255425 -0.082361  1.065235\n",
      "2       1.109969 -1.514654  1.800499  0.066084\n",
      "3      -0.684093 -1.387024  1.247203  0.178228\n",
      "4      -0.237033  0.817739  0.095921  0.538196\n",
      "...          ...       ...       ...       ...\n",
      "284802  1.991691  1.914428 -2.606837  2.711941\n",
      "284803 -0.025693  0.584800  1.058415  0.915802\n",
      "284804  0.313502  0.432454  3.031260  0.063119\n",
      "284805  0.509928  0.392087  0.623708 -0.962886\n",
      "284806 -0.660377  0.486180 -0.649617 -0.031513\n",
      "\n",
      "[284807 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dacc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [2],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [4, 6, 8],\n",
       "                                        'min_samples_split': [5, 7, 10],\n",
       "                                        'n_estimators': [20]},\n",
       "                   random_state=101, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search\n",
    "# 구간 정해주고 그 구간 안 랜덤으로 숫자 뽑아서 실험\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#트리의 노드를 반복적으로 분할\n",
    "\n",
    "\"\"\"\n",
    "criterion: 노드 분할 기준 정하는 매개변수, entropy/ gini 중 택일\n",
    "max_depth: 트리의 최대깊이 제한 과적합 방지\n",
    "max_features: 특성 개수의 제곱근 만큼 특성 선택\n",
    "min_samples_leaf: 리프 노드가 되기 위한 최소 샘플 수 지정, 이 값보다 작으면 더이상\n",
    "                    분할하지 않고 리프 노드가 된다\n",
    "min_samples_split: 노드를 분할하기 위한 최소 샘플 수 지정, 이 값보다 작으면 더이상 \n",
    "                    분할 하지 않고 리프 노드 됨\n",
    "n_estimators: 생성할 트리의 개수 지정\"\"\"\n",
    "\n",
    "random_search={'criterion':['entropy','gini'],\n",
    "              'max_depth':[2],\n",
    "              'max_features':['auto','sqrt'],\n",
    "              'min_samples_leaf':[4,6,8],\n",
    "              'min_samples_split':[5,7,10],\n",
    "              'n_estimators':[20]}\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "model=RandomizedSearchCV(estimator=clf,param_distributions=random_search,n_iter=10,\n",
    "                        cv=4, verbose=1,random_state=101,n_jobs=-1)\n",
    "\"\"\"\n",
    "estimator: 탐색할 모델\n",
    "param_distributions: 탐색할 하이퍼파라미터 공간, 이 공간에서 무작위 샘플링\n",
    "n_iter: 랜덤 탐색에서 시도할 하이퍼파라미터 조합의 수\n",
    "cv: 교차검정을 수행할 폴드 수\n",
    "n_jobs: 적합성과 예측성을 위해 병렬로 실행할 작업 수\n",
    "        병렬 처리에 사용할 cpu 코어의 수\n",
    "        -1로 설정 시 가능한 모든 코어 사용\"\"\"\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500d2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 2, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba661ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85299\n",
      "           1       0.84      0.56      0.67       144\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.78      0.83     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Random Search:  0.9990754069964772\n"
     ]
    }
   ],
   "source": [
    "randompredict=model.best_estimator_.predict(x_test)\n",
    "print(classification_report(y_test,randompredict))\n",
    "print(\"\\nRandom Search: \", accuracy_score(y_test,randompredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82478779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['entropy', 'gini'], 'max_depth': [2],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [4, 6, 8],\n",
       "                         'min_samples_split': [5, 7, 10],\n",
       "                         'n_estimators': [20]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search\n",
    "\"\"\"\n",
    "random search와 차이점\n",
    "random: 탐색 범위 주어지고 해당 범위 내 임의 조합 찾아 탐색\n",
    "grid: 탐색할 값이 주어지고 모든 조합 탐색\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search={'criterion':['entropy','gini'],\n",
    "            'max_depth':[2],\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'min_samples_leaf':[4,6,8],\n",
    "            'min_samples_split':[5,7,10],\n",
    "            'n_estimators':[20]}\n",
    "clf=RandomForestClassifier()\n",
    "model=GridSearchCV(estimator=clf, param_grid=grid_search,cv=4,verbose=5,n_jobs=-1)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7268f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2bda45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85299\n",
      "           1       0.83      0.69      0.76       144\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.92      0.85      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "Grid Search:  0.9992509626300574\n"
     ]
    }
   ],
   "source": [
    "gridpredict=model.best_estimator_.predict(x_test)\n",
    "print(classification_report(y_test,gridpredict))\n",
    "print(\"\\nGrid Search: \",accuracy_score(y_test,gridpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2f1b9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 10.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from hyperopt) (1.21.5)\n",
      "Requirement already satisfied: six in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from hyperopt) (1.7.3)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ------------------------------------- 840.9/840.9 kB 13.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "     -------------------------------------- 200.5/200.5 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492055 sha256=24695b4636231947cf6483ed6a7e6e98e03b4fbf168cdb8527c3197fcee56e93\n",
      "  Stored in directory: c:\\users\\tlsdu\\appdata\\local\\pip\\cache\\wheels\\52\\2a\\fc\\520209cfa6448febd490720a0b09036cb367628f7c4e9cc172\n",
      "Successfully built future\n",
      "Installing collected packages: py4j, tqdm, networkx, future, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-2.2.1 future-0.18.3 hyperopt-0.2.7 networkx-2.6.3 py4j-0.10.9.7 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization\n",
    "\"\"\"\n",
    "1. 관측 데이터 기반 목적 함수를 추정: Gaussian Process\n",
    "2. 추정 모델 기반 탐색한 파라미터 선택: Acquisition Function\n",
    "-평균이 최대\n",
    "-분산이 최대\n",
    "3. 다음 관측 데이터에 추가\n",
    "\n",
    "목적함수와 하이퍼 파라미터 조합을 대상으로 평가 후 관측 데이터에 추가하는 과정을 \n",
    "반복하면서 순차적으로 업데이트 하여 최적의 조합을 탐색하는 방법\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "입력값 x 받는 미지의 목적 함수 f(x) 상정 후 해당 함숫값을 최대로 만드는 최적해를\n",
    "찾는 것을 목적으로 한다. \n",
    "두가지 필수 요소 존재\n",
    "1. Surrogate Model은 현재까지 조사된 입력값-함숫값 점 바탕으로 미지의 목적 함수 형태\n",
    "에 대한 확률적인 추정을 수행하는 모델\n",
    "2. Acquisition Function은 목적 함수에 대한 현재까지의 확률적 추정 결과를 바탕으로\n",
    "최적 입력값을 찾는 데 있어 가장 유용할 만한 다음 입력값 후보를 추천해 주는 함수 지칭\n",
    "\"\"\"\n",
    "\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bd48121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in          \n",
      "database. History logging moved to new session        \n",
      "209                                                   \n",
      "100%|██████████| 20/20 [01:53<00:00,  5.66s/trial, best loss: 0.9982544491482915]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0,\n",
       " 'max_depth': 10.0,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 0.10591490048784225,\n",
       " 'min_samples_split': 0.21029259237553422,\n",
       " 'n_estimators': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "space={'criterion':hp.choice('criterion',['entropy','gini']),\n",
    "      'max_depth':hp.quniform('max_depth',10,12,10),\n",
    "      'max_features':hp.choice('max_features',['auto','sqrt','log2',None]),\n",
    "      'min_samples_leaf':hp.uniform('min_samples_leaf',0,0.5),\n",
    "      'min_samples_split':hp.uniform('min_samples_split',0,1),\n",
    "      'n_estimators':hp.choice('n_estimators',[10,50])}\n",
    "#hp.quniform 은 실수 값 반환하지만 주어진 간격에 따라 양자화된다\n",
    "# 10 부터 12까지의 값 균일하게 샘플링 하지만 반환된 값은 10,11,12 중 하나일 것이다.\n",
    "\n",
    "def objective(space):\n",
    "    hopt=RandomForestClassifier(criterion=space['criterion'],\n",
    "                               max_depth=space['max_depth'],\n",
    "                               max_features=space['max_features'],\n",
    "                               min_samples_leaf=space['min_samples_leaf'],\n",
    "                               min_samples_split=space['min_samples_split'],\n",
    "                               n_estimators=space['n_estimators'])\n",
    "    accuracy=cross_val_score(hopt,x_train,y_train,cv=4).mean()\n",
    "    return {'loss':accuracy,'status':STATUS_OK}\n",
    "\n",
    "trials=Trials()\n",
    "best=fmin(fn=objective,\n",
    "         space=space,\n",
    "         algo=tpe.suggest,\n",
    "         max_evals=20,\n",
    "         trials=trials)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f74ebd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85299\n",
      "           1       0.00      0.00      0.00       144\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.50      0.50      0.50     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "crit={0:'entropy',1:'gini'}\n",
    "feat={0:'auto',1:'sqrt',2:'log2',3:None}\n",
    "est={0:10,1:50,2:75,3:100,4:125}\n",
    "\n",
    "trainedforest=RandomForestClassifier(criterion=crit[best['criterion']],\n",
    "                                    max_depth=best['max_depth'],\n",
    "                                    max_features=feat[best['max_features']],\n",
    "                                    min_samples_leaf=best['min_samples_leaf'],\n",
    "                                    min_samples_split=best['min_samples_split'],\n",
    "                                    n_estimators=est[best['n_estimators']]\n",
    "                                    ).fit(x_train,y_train)\n",
    "\n",
    "predictionforest=trainedforest.predict(x_test)\n",
    "print(classification_report(y_test,predictionforest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6509f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization:  0.9983146659176293\n"
     ]
    }
   ],
   "source": [
    "print(\"Bayesian Optimization: \",accuracy_score(y_test,predictionforest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bfe1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 8.6 MB/s eta 0:00:00\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
      "     ------------------------------------- 226.8/226.8 kB 14.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-2.0.25-cp37-cp37m-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 11.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from optuna) (22.0)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "     -------------------------------------- 153.2/153.2 kB 9.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.4.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.3)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from alembic>=1.5.0->optuna) (5.2.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB ? eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp37-cp37m-win_amd64.whl (291 kB)\n",
      "     ------------------------------------- 291.4/291.4 kB 17.6 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: typing-extensions, PyYAML, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed Mako-1.2.4 PyYAML-6.0.1 alembic-1.12.1 colorlog-6.8.2 greenlet-3.0.3 optuna-3.5.0 sqlalchemy-2.0.25 typing-extensions-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "def objective(trial):\n",
    "    iris=sklearn.datasets.load_iris()\n",
    "    x,y=iris.dat,iris.target\n",
    "    \n",
    "    classifier_name=trai.suggest_categorical('classifier',['SVC','RandomForest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4473b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "     ---------------------------------------- 100.3/100.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-optimize) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-optimize) (1.1.1)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-23.5.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-optimize) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-23.5.8 scikit-optimize-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf69d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_12652\\262957053.py\", line 32, in <module>\n",
      "    estimator=create_model(),\n",
      "TypeError: create_model() missing 4 required positional arguments: 'learning_rate', 'num_filters', 'kernel_size', and 'dropout_rate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_12652\\262957053.py\", line 32, in <module>\n",
      "    estimator=create_model(),\n",
      "TypeError: create_model() missing 4 required positional arguments: 'learning_rate', 'num_filters', 'kernel_size', and 'dropout_rate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_12652\\262957053.py\", line 32, in <module>\n",
      "    estimator=create_model(),\n",
      "TypeError: create_model() missing 4 required positional arguments: 'learning_rate', 'num_filters', 'kernel_size', and 'dropout_rate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "search_space = {\n",
    "    'learning_rate': Real(0.0001, 0.1, prior='log-uniform'),\n",
    "    'num_filters': Integer(16, 64),\n",
    "    'kernel_size': Integer(3, 5),\n",
    "    'dropout_rate': Real(0.0, 0.5)\n",
    "}\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator=create_model(),\n",
    "    search_spaces=search_space,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "# Define CNN model\n",
    "def create_model(learning_rate, num_filters, kernel_size, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Conv2D(num_filters, kernel_size, activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(num_filters * 2, kernel_size, activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fit model with Bayesian Optimization\n",
    "result = bayes_cv_tuner.fit(X_train, y_train)\n",
    "\n",
    "# Get best hyperparameters and evaluate on test set\n",
    "best_params = result.best_params_\n",
    "best_model = result.best_estimator_\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_15036\\3922099276.py\", line 55, in <module>\n",
      "    result = bayes_cv_tuner.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\skopt\\searchcv.py\", line 466, in fit\n",
      "    super().fit(X=X, y=y, groups=groups, **fit_params)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 793, in fit\n",
      "    scorers = check_scoring(self.estimator, self.scoring)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 450, in check_scoring\n",
      "    % estimator\n",
      "TypeError: estimator should be an estimator implementing 'fit' method, <function create_model at 0x000002029D41A678> was passed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_15036\\3922099276.py\", line 55, in <module>\n",
      "    result = bayes_cv_tuner.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\skopt\\searchcv.py\", line 466, in fit\n",
      "    super().fit(X=X, y=y, groups=groups, **fit_params)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 793, in fit\n",
      "    scorers = check_scoring(self.estimator, self.scoring)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 450, in check_scoring\n",
      "    % estimator\n",
      "TypeError: estimator should be an estimator implementing 'fit' method, <function create_model at 0x000002029D41A678> was passed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsdu\\AppData\\Local\\Temp\\ipykernel_15036\\3922099276.py\", line 55, in <module>\n",
      "    result = bayes_cv_tuner.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\skopt\\searchcv.py\", line 466, in fit\n",
      "    super().fit(X=X, y=y, groups=groups, **fit_params)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 793, in fit\n",
      "    scorers = check_scoring(self.estimator, self.scoring)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 450, in check_scoring\n",
      "    % estimator\n",
      "TypeError: estimator should be an estimator implementing 'fit' method, <function create_model at 0x000002029D41A678> was passed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\tlsdu\\anaconda3\\envs\\mine\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "search_space = {\n",
    "    'learning_rate': Real(0.0001, 0.1, prior='log-uniform'),\n",
    "    'num_filters': Integer(16, 64),\n",
    "    'kernel_size': Integer(3, 5),\n",
    "    'dropout_rate': Real(0.0, 0.5)\n",
    "}\n",
    "\n",
    "# Define CNN model\n",
    "def create_model(learning_rate, num_filters, kernel_size, dropout_rate):\n",
    "    model = Sequential([\n",
    "        Conv2D(num_filters, kernel_size, activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(num_filters * 2, kernel_size, activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize Bayesian Optimization\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator=create_model,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit model with Bayesian Optimization\n",
    "result = bayes_cv_tuner.fit(X_train, y_train)\n",
    "\n",
    "# Get best hyperparameters and evaluate on test set\n",
    "best_params = result.best_params_\n",
    "best_model = result.best_estimator_\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bf0534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 248\n",
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from bayesian-optimization) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from bayesian-optimization) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from bayesian-optimization) (1.0.2)\n",
      "Requirement already satisfied: colorama>=0.4.6 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tlsdu\\anaconda3\\envs\\mine\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.1)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f039045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e0a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e94021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lr=1e-3, dropout_rate=0.5):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    base_model.trainable = False  # 기본 모델의 가중치를 고정합니다.\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a515c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(lr, dropout_rate):\n",
    "    model = build_model(lr, dropout_rate)\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "    accuracy = np.amax(history.history['val_accuracy'])  # 검증 정확도의 최댓값을 반환합니다.\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f3b046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... |    lr     |\n",
      "-------------------------------------------------\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 6s 0us/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.5855   \u001b[0m | \u001b[0m0.2668   \u001b[0m | \u001b[0m0.007231 \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.605    \u001b[0m | \u001b[95m0.1      \u001b[0m | \u001b[95m0.003093 \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.6041   \u001b[0m | \u001b[0m0.1435   \u001b[0m | \u001b[0m0.003752 \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.6011   \u001b[0m | \u001b[0m0.1436   \u001b[0m | \u001b[0m0.003685 \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.5975   \u001b[0m | \u001b[0m0.143    \u001b[0m | \u001b[0m0.003873 \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.6063   \u001b[0m | \u001b[95m0.1003   \u001b[0m | \u001b[95m0.003499 \u001b[0m |\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m0.6251   \u001b[0m | \u001b[95m0.2583   \u001b[0m | \u001b[95m0.001698 \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.5848   \u001b[0m | \u001b[0m0.4551   \u001b[0m | \u001b[0m0.004527 \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.602    \u001b[0m | \u001b[0m0.2729   \u001b[0m | \u001b[0m0.003585 \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6185   \u001b[0m | \u001b[0m0.258    \u001b[0m | \u001b[0m0.002004 \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6058   \u001b[0m | \u001b[0m0.1002   \u001b[0m | \u001b[0m0.003121 \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.5979   \u001b[0m | \u001b[0m0.1433   \u001b[0m | \u001b[0m0.003671 \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "pbounds = {'lr': (1e-4, 1e-2), 'dropout_rate': (0.1, 0.5)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "optimizer.maximize(init_points=2, n_iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb7de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
