# RNN
> Sequence data

ex) 음성인식, 자연어 -- 문맥이 있는 데이터, 이전 단어 이해해야 전체 맥락 이해 가능(series data)

![image](https://github.com/moonie1253/AI-study/assets/157441976/cf0de986-84b0-415a-9f53-3386b311a257)

A의 결과가 다시 A로 들어가서 루프 만듦. 현 state가 다음 state에 영향

  - RNN은 state 계산시 전의 state를 사용하게 된다는게 포인트

## RNN applications
- language modeling
- speech recognition
- machine translation
- conversation modeling/ question answering
- image/ video captioning
- image/ music/ dance generation

### 응용
![image](https://github.com/moonie1253/AI-study/assets/157441976/46d8ec73-34a7-4b9e-ac48-02dd9ecc5fd9)
- one to one: vanilla neural network
- one to many: image captioning
- many to one: sentiment classification
- many to many: machine translation
- many to many: video classification on frame level

> multi-layer RNN 쓰면 더 복잡한 학습 가능
>
> 대신 layer 많아지면 학습 어려워지니까 LSTM/ GRU 사용

&nbsp;

## vanilla RNN 계산
![image](https://github.com/moonie1253/AI-study/assets/157441976/4f846eac-4810-4d4c-a50f-d38af425a3d3)

&nbsp;

fw 에는 activation function 같은 게 들어가나 보네

&nbsp;

![image](https://github.com/moonie1253/AI-study/assets/157441976/40139ae6-741a-49ef-89ba-504a0d482c59)

&nbsp;

실제 input x 가 ['h','e','l','l','o'] 일 경우 각 문자를 vector로 만들고 hidden layer 값을 state라 가정 -> 벡터 연산 진행

&nbsp;

![image](https://github.com/moonie1253/AI-study/assets/157441976/299eb113-3a7a-4c94-9e27-1fb84613b5cb)

&nbsp;

![image](https://github.com/moonie1253/AI-study/assets/157441976/c4349001-40ba-41b1-9e63-ded51cb7f4e2)

- 일단 각 letter마다 벡터 하나를 임의 부여
- 위에 제일 큰 점수 받은 letter이 다음에 올 것이라고 예상(이때 함수가 역할을 하는 것임, 제대로 예측하도록 함수를 조정)
- 예측에 성공했으면, 그 예측이 다음 input이 되어 그 다음 output(letter)을 예측 
